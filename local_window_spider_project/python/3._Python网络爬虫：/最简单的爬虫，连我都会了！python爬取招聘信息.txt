b'\xe6\x9c\x80\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe7\x88\xac\xe8\x99\xab\xef\xbc\x8c\xe8\xbf\x9e\xe6\x88\x91\xe9\x83\xbd\xe4\xbc\x9a\xe4\xba\x86\xef\xbc\x81python\xe7\x88\xac\xe5\x8f\x96\xe6\x8b\x9b\xe8\x81\x98\xe4\xbf\xa1\xe6\x81\xaf' http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhex75f4tgALXsbVXZnpE2KrWkL443BibwN9aFQMmPDvj1EGDDpna9V6w/0?wx_fmt=png
 效果就是这样，目前还没有学到如何把这些数据存放起来。我想之后在秦老师这边学了数据库，就可以操作了吧。


回家后复习了一下，练习在某疼的招聘页面爬取信息，整理了一下写代码的过程，一方面是自己记录一下，另一方面也想和大家一起分享~
 （如果你是程序大佬，围观一下就好了，<span style="box-sizing: border-box;color: rgb(51, 51, 51);">不要嘲笑我这个小小白呀~</span>如果我有哪里说错了，恳请帮忙指正！）


建议先了解一下基础的html语言和python语言，html只要知道有标签&lt;&gt;&lt;/&gt;这种东西，网页大概是怎么排布的就ok了，python的话按秦老师的课程，学到“第三方包”这一节就差不多了。


也可以在廖雪峰老师或w3school上了解。
 首先你要有python和Sublime（直接在Jupyter Notebook也阔以哦~），并且要有Chromedriver插件。


程序和环境变量
https://ask.hellobi.com/blog/toughsummer/10834


包和chrome插件
https://ask.hellobi.com/blog/toughsummer/10740


做好准备工作，我们开工啦！（搓手）
  

然后是加载包。你可以把包当成python的插件（反正现阶段我是这么理解的……），用到什么功能，就加载相应的包。
  

https://www.zhihu.com/question/38857862/answer/90981260


第一句的selenium包，准确来说是一个python实现自动化操作的包。自动化操作就是，告诉电脑该干嘛，让你的电脑自己干。比如自己开个软件，自己关掉窗口，当然也包括自己打开网页并且把网页上的内容摘下来。所以我们可以用selenium包来做爬虫。


能用来做爬虫的包有很多，天善的视频课程里有个免费爬虫课用的beautifulsoup，也很好。但是它操作很快，有时候会被对方发现是机器人，从而被禁掉。所以我们一开始还是用selenium入门学习比较好。


Webdriver就是selenium包里的一个类，用来进行网页相关操作。


载入以后，我们第一步是让电脑认识浏览器，打开网页。
  

然后我们用get方法让dr访问招聘网页的地址，就是某疼社招技术岗页面。


代码先写到这里，下一步我们来分析一下页面上的内容。


我们自己用chrome浏览器打开这个网页，看到页面是这样的。
http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhRFiaOYbnTBBNJd2E0uiciardfA8wNKSb6VCib1DowIE4X5PARCBpichcOFA/0?wx_fmt=png
怎么让程序看到这一部分的内容，并抓到它呢？


我们按F12（右键-检查也可以），用开发者模式看一看它的代码。


http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhtfhlhVHkJZSnyLQR1h0ciaBS1tIMy6F4wHFX7c7icOPYk1oZCwbHoyyw/0?wx_fmt=png
点“1”这个小鼠标，再把鼠标移到网页上我们要找的内容，发现文字的底色改变了。


这个功能就是用来定位网页上的元素，找到对应的代码。


点一下变色的内容，发现下面的代码也跳转到了对应位置。
http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhJAyaCyuLeR8nesUoQoFq7bIibsQJe1sPybYPJMMkJ3FgEZaFs5ib3Xrg/0?wx_fmt=png


我们把鼠标在这附近移动，看到对应元素的变化。
 http://mmbiz.qpic.cn/mmbiz_gif/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhNM6zmEdVP2Ue81D5b2BAOFgktLUPbo35R3icJO5G8F1dSMicSJ7lZWwQ/0?wx_fmt=gif


可以看到，这块其实是个表格，每个”&lt;tr&gt;&lt;/tr&gt;”标签都是一行，class名为“h”的行是标题行，class名为even的是奇数行，odd是偶数行。


一开始看到这个奇偶数，非常生气！为什么它要把行弄得不一样呢！如果每行同一个名字，我一句话就可以找到它，可偏偏不同！


后来仔细看了一下页面，发现奇数行是白底，偶数行是蓝底，看来是为了表格更美观而设计的。那没办法，我们只好后面稍微辛苦一点了。


接下来我们就定位到相应的元素去。


写代码：
  

接着用main_content这个变量获取网页中class名为“tablelist”的元素。


Evens则是名为“even”的元素们。


要注意，因为每一个奇数行都叫“even”，所以我们要find_element<strong style="box-sizing: border-box;font-weight: bold;">s</strong>_by_class_name，这一步得到的结果也是多个元素，所以evens是一个list列表，里面存了好多个元素。


然后我们要从evens里的每个元素中，提取到每一列的对应信息。


所以先写个for循环，遍历evens里的每个even
  http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhGUmsgRm2MExB1WhJRbRaicuaJdaoibkC5CK8on1EgVMzRh1qPWeptuVg/0?wx_fmt=png
后面四列很好弄，就是单元格里的纯字符串或数值而已，第一列的话有个超链接，看起来非常复杂。Ok，那我们先搞下面的。


但问题来了，现在没有class或者id了，咋办捏。没事，我们还有个by xpath方法。


Xpath就是&lt;*&gt;&lt;/*&gt;的这个*，很好理解的。
 好了，后面四个信息都拿到了。


其实第一个也拿到了，因为第一列就是第一个td元素，所以存放在td[0]里面。那么我们只要在td[0]里面，用xpath再找到下面的&lt;a……&gt;&lt;/a&gt;，然后取出里面的文本就可以了。
   http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhlZqYic4qJ5DpUomrlPmh3IQfz8qxgZaYXXBcvNf9djDFLu201css92A/0?wx_fmt=png


心情愉悦！！


接着加上序号，再把odd行也抓下来~


大家可以自己试着写一写odd行的抓取代码，其实一样的哦~我就不重复了。还可以给它们加上编号：
http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhua8EmLvdM9fxicm0Vsvz58ibUIgicSqYpfEiaSwfUhKmMfJO8Vlbdmmkyw/0?wx_fmt=png


接着我们学怎么翻页。类似的，找到翻页的按钮
http://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttvdCx8tAmuz1RWmvibOqicLHhyoeoibicRiaUKRQujvGKD6A4PlbkwQ8KxcCqhibvzNCAFlOw94yS3F6iaYg/0?wx_fmt=png


哟！发现它有个id属性！id是最开心的，因为每个网页上元素的id必须唯一，不用担心有重复值。我们通过next这个id定位到按钮，然后用click()方法点击它就可以啦。
 